{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4qMOMq0GzIE"
      },
      "source": [
        "**Deep Learning course - Sharif University of Technology - EE Department**\n",
        "\n",
        "**HW2 - Q2**\n",
        "\n",
        "**this code is developed based on this github repository: **\n",
        "\n",
        "https://github.com/cozheyuanzhangde/Forward-Forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nch-9SyDNvNz",
        "outputId": "b603b25d-a550-4938-a907-04753c156f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your student id: 99101579\n",
            "your name: Radin Khayyam\n"
          ]
        }
      ],
      "source": [
        "student_id =  99101579\n",
        "student_name = 'Radin Khayyam'\n",
        "\n",
        "print(\"your student id:\", student_id)\n",
        "print(\"your name:\", student_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OHKna2kIZXV6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from scipy.signal import convolve2d\n",
        "from torch import tensor, Tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "PPsPg3uCZkHo"
      },
      "outputs": [],
      "source": [
        "def MNIST_loaders(train_batch_size=50000, test_batch_size=10000):\n",
        "\n",
        "    # Define data transformations\n",
        "    # we used torch.flatten to reshape 28*28 pics to a 784*1 vector\n",
        "    transform = Compose([ToTensor(), Lambda(lambda x: torch.flatten(x))])\n",
        "\n",
        "    # Create training data loader\n",
        "    train_dataset = MNIST('./data/', train=True, download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "    # Create test data loader\n",
        "    test_dataset = MNIST('./data/', train=False, download=True, transform=transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIzdFA6QX8U2"
      },
      "source": [
        "**Supervised method:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "WqSXyiIgZthe"
      },
      "outputs": [],
      "source": [
        "# Generate positive data\n",
        "# We put correct label on first 10 pixels of data for this part\n",
        "def gen_pos_data(x, y):\n",
        "    labeled_data = x.clone()\n",
        "    labeled_data[:,0:10] = 0\n",
        "    if(type(y)==int):\n",
        "      for i in range(x.shape[0]):\n",
        "        labeled_data [i , y] = 1.0\n",
        "    else:\n",
        "      for i in range(x.shape[0]):\n",
        "        labeled_data [i , y[i]] = 1.0\n",
        "\n",
        "    return labeled_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "-mQ9XrPrwnGm"
      },
      "outputs": [],
      "source": [
        "# Generate negative data\n",
        "# We put random wrong label on first 10 pixels of data for this part\n",
        "def gen_neg_data(x,y):\n",
        "    labeled_data = x.clone()\n",
        "    labeled_data[:,0:10] = 0\n",
        "    rand_idx = torch.randperm(x.size(0))\n",
        "    y_rand = y[rand_idx]\n",
        "    for i in range(x.shape[0]):\n",
        "      labeled_data [i , y_rand[i]] = 1.0\n",
        "\n",
        "    return labeled_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t245gBQWHL17"
      },
      "source": [
        "in this section we show an example what we did in generating positive and negative data from original data.\n",
        "As you can see, in positive data we put the right label in first 10 pixels, but in negative data we put another random label in these pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "dBLzLL5hHKim",
        "outputId": "3d80d7e2-f29f-4f9d-dcfa-ad7c593af454"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Negative Data')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAAEOCAYAAAAOmGH2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkEUlEQVR4nO3deXhN1/7H8c+R6EmIhAwIDZKgaigaV5VG0EFraGmNNU/VVutq0VbbH8I1tbeGpq1bqmjorZo66KC0XKpo1S1uUzpJb6uDIUKJKcn6/eHJvo4kJ4csIrxfz5M/stc+a6992N+cz9l7r+0yxhgBAAAAgEUlinoAAAAAAC4/BA0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWEfQAAAAAGAdQQMAAACAdQSNi2Ts2LFyuVzn9dp58+bJ5XIpNTXV7qDOkJqaKpfLpXnz5l2wbQC48Fwul8aOHevTutWqVVPfvn0v6HgAXFkK83kHlx+CRgG+/vpr9ezZU5UrV5bb7ValSpXUo0cPff3110U9tCKxdu1auVwu58ftdqtChQpq0aKFJk6cqH379p133ykpKRo7duwFDVTAxZTzJUHOT0BAgGrWrKmHHnpIf/zxx0UZw2effaaxY8cqPT39omzPF9WqVXPekxIlSqhs2bKqV6+e7rvvPm3evLlQfU+cOFFvvfWWnYECF1FOvQgICNCePXtytbdo0UJ169YtgpHllpGRobFjx2rt2rVFPRRHTsDJ+SlVqpSqVKmi9u3ba+7cuTpx4sR59/3+++/7/AUOPBE0vFi2bJmuv/56ffzxx+rXr59eeuklDRgwQGvWrNH111+v5cuX+9zX008/rWPHjp3XOHr16qVjx46patWq5/X6C2Ho0KFKTk7WrFmzNHLkSIWGhmrMmDG69tpr9cknn5xXnykpKUpMTCRo4LIzbtw4JScn64UXXlDTpk01c+ZM3XjjjcrIyLC+rWPHjunpp592fv/ss8+UmJiYZ9DYtWuXZs+ebX0MvmjQoIGSk5P12muvadKkSWrZsqXeffddNWnSRI8++uh590vQQHF34sQJTZ48uaiH4VVGRoYSExPzDBqF+bxjw8yZM5WcnKykpCQNHDhQaWlp6t+/vxo3bqyff/75vPp8//33lZiYaHmkVwb/oh7ApeqHH35Qr169FBMTo3Xr1ikiIsJp++tf/6r4+Hj16tVL27dvV0xMTL79HD16VKVLl5a/v7/8/c/v7fbz85Ofn995vfZCiY+PV6dOnTyWbdu2TbfddpvuuecepaSkKDIysohGB1xa7rjjDjVq1EiSNHDgQIWFhWnq1Kl6++231b17d6vbCggI8Hldt9ttddvnonLlyurZs6fHsilTpujee+/VtGnTVKNGDT3wwANFNDqg6DRo0ECzZ8/WqFGjVKlSpaIezjkrzOcdGzp16qTw8HDn99GjR2vhwoXq3bu3OnfurE2bNhXZ2K5EnNHIx7PPPquMjAzNmjXLI2RIUnh4uF5++WUdPXpUzzzzjLM857RdSkqK7r33XpUrV0433XSTR9uZjh07pqFDhyo8PFxlypTRnXfeqT179uS6xjqvezSqVaumdu3a6dNPP1Xjxo0VEBCgmJgYvfbaax7bSEtL04gRI1SvXj0FBQUpODhYd9xxh7Zt22bpnfqf+vXra/r06UpPT9cLL7zgLP/pp5/04IMP6pprrlFgYKDCwsLUuXNnj/2ZN2+eOnfuLElq2bKlc+oz59uSt99+W23btlWlSpXkdrsVGxur8ePHKysry/p+ABdaq1atJEm7d++WJGVmZmr8+PGKjY2V2+1WtWrV9OSTT+Y61b9lyxa1bt1a4eHhCgwMVHR0tPr37++xzpn1Y+zYsRo5cqQkKTo62jmuco69M+/R2LJli1wul+bPn59rvCtXrpTL5dKKFSucZXv27FH//v1VoUIFud1u1alTR6+++mqh3pfAwEAlJycrNDRUEyZMkDHGafv73/+upk2bKiwsTIGBgYqLi9OSJUty7fvRo0c1f/58Z19z9s+XOgRcCp588kllZWX5fFZjwYIFiouLU2BgoEJDQ9WtW7c8v7l/8cUXFRMTo8DAQDVu3Fjr169XixYt1KJFC2edkydPavTo0YqLi1NISIhKly6t+Ph4rVmzxlknNTXV+VyUmJjoHGtn1p0zP+/UrVtXLVu2zDWe7OxsVa5c2eNLy+zsbE2fPl116tRRQECAKlSooMGDB+vgwYM+vRf56dGjhwYOHKjNmzdr1apVzvL169erc+fOqlKlitxut6KiovTII494nJHp27evXnzxRUnyuDQrhy+16UpG0MjHu+++q2rVqik+Pj7P9ubNm6tatWp67733crV17txZGRkZmjhxogYNGpTvNvr27aukpCS1adNGU6ZMUWBgoNq2bevzGL///nt16tRJt956q5577jmVK1dOffv29bh/5Mcff9Rbb72ldu3aaerUqRo5cqR27NihhIQE/frrrz5vy1edOnVSYGCgPvroI2fZF198oc8++0zdunXT888/r/vvv18ff/yxWrRo4Vw60rx5cw0dOlTS6SKbnJys5ORkXXvttZJOB5GgoCA9+uijmjFjhuLi4jR69Gg98cQT1vcBuNB++OEHSVJYWJik02c5Ro8ereuvv17Tpk1TQkKCJk2apG7dujmv2bt3r2677TalpqbqiSeeUFJSknr06OH127m7777bOWMybdo057g6+8sTSWrUqJFiYmL05ptv5mpbtGiRypUrp9atW0uS/vjjDzVp0kSrV6/WQw89pBkzZqh69eoaMGCApk+fft7viyQFBQWpY8eO2rNnj1JSUpzlM2bMUMOGDTVu3DhNnDhR/v7+6ty5s0cNTk5OltvtVnx8vLOvgwcPluRbHQIuBdHR0erdu7dmz55d4N/pCRMmqHfv3qpRo4amTp2qYcOG6eOPP1bz5s09LpecOXOmHnroIV199dV65plnFB8frw4dOuiXX37x6O/w4cN65ZVX1KJFC02ZMkVjx47Vvn371Lp1a3311VeSpIiICM2cOVOS1LFjR+dYu/vuu/McY9euXbVu3Tr9/vvvHss//fRT/frrrx51bvDgwRo5cqSaNWumGTNmqF+/flq4cKFat26tU6dO+foW5qlXr16S5PH5ZPHixcrIyNADDzygpKQktW7dWklJSerdu7fHmG699VZJcvY1OTnZafelNl3RDHJJT083ksxdd93ldb0777zTSDKHDx82xhgzZswYI8l0794917o5bTm+/PJLI8kMGzbMY72+ffsaSWbMmDHOsrlz5xpJZvfu3c6yqlWrGklm3bp1zrK9e/cat9tthg8f7iw7fvy4ycrK8tjG7t27jdvtNuPGjfNYJsnMnTvX6z6vWbPGSDKLFy/Od5369eubcuXKOb9nZGTkWmfjxo1GknnttdecZYsXLzaSzJo1a3Ktn1cfgwcPNqVKlTLHjx/3OmagqOQcu6tXrzb79u0zP//8s3njjTdMWFiYCQwMNL/88ov56quvjCQzcOBAj9eOGDHCSDKffPKJMcaY5cuXG0nmiy++8LrNs+vHs88+m6t+5Khatarp06eP8/uoUaNMyZIlTVpamrPsxIkTpmzZsqZ///7OsgEDBpjIyEizf/9+j/66detmQkJC8jxez95u27Zt822fNm2akWTefvttZ9nZfZ48edLUrVvXtGrVymN56dKlPfYpv9cbk3cdAopKTr344osvzA8//GD8/f3N0KFDnfaEhARTp04d5/fU1FTj5+dnJkyY4NHPjh07jL+/v7P8xIkTJiwszPzlL38xp06dctabN2+ekWQSEhKcZZmZmebEiRMe/R08eNBUqFDBowbs27cvV63JcfbnnV27dhlJJikpyWO9Bx980AQFBTnH5vr1640ks3DhQo/1PvzwwzyX57fdffv25dl+8OBBI8l07NjRWZZXXZg0aZJxuVzmp59+cpYNGTLE5PeR2dfadKXijEYe/vzzT0lSmTJlvK6X03748GGP5ffff3+B2/jwww8lSQ8++KDH8ocfftjncdauXdvjjEtERISuueYa/fjjj84yt9utEiVO/zNnZWXpwIEDCgoK0jXXXKOtW7f6vK1zERQU5LyH0unLIXKcOnVKBw4cUPXq1VW2bFmfx3BmH3/++af279+v+Ph4ZWRkaOfOnfYGD1wAt9xyiyIiIhQVFaVu3bopKChIy5cvV+XKlfX+++9LUq4boIcPHy5JzrdiZcuWlSStWLGi0N/s5adr1646deqUli1b5iz76KOPlJ6erq5du0qSjDFaunSp2rdvL2OM9u/f7/y0bt1ahw4dKnRtCQoKkqR868jBgwd16NAhxcfHn1cNOd86BFwsMTEx6tWrl2bNmqXffvstz3WWLVum7OxsdenSxeM4rFixomrUqOFc7rRlyxYdOHBAgwYN8rh3okePHipXrpxHn35+frrqqqsknb6MKS0tTZmZmWrUqNF5Hyc1a9ZUgwYNtGjRImdZVlaWlixZovbt2zvH5uLFixUSEqJbb73VY3/i4uIUFBTkcfnW+Siorhw9elT79+9X06ZNZYzRv//9b5/6LWxtutwRNPKQEyDO/M+Yl/wCSXR0dIHb+Omnn1SiRIlc61avXt3ncVapUiXXsnLlynlcy5idne3cWOl2uxUeHq6IiAht375dhw4d8nlb5+LIkSMe78mxY8c0evRoRUVFeYwhPT3d5zF8/fXX6tixo0JCQhQcHKyIiAjnRtILtR+ALS+++KJWrVqlNWvWKCUlRT/++KNzGVJOLTj72K9YsaLKli2rn376SZKUkJCge+65R4mJiQoPD9ddd91V6Ckbz1a/fn3VqlXL4wPBokWLFB4e7txXsm/fPqWnpzv3r535069fP0mnL/MqjCNHjkjyrK0rVqxQkyZNFBAQoNDQUOfyDV+Pfxt1CLiYnn76aWVmZuZ7r8Z3330nY4xq1KiR61j85ptvnOMwp4acXWP8/f1VrVq1XP3Onz9f1113nQICAhQWFqaIiAi99957hTpOunbtqg0bNjjT9q5du1Z79+51vsDI2Z9Dhw6pfPnyufbnyJEjF6Su/Pe//1Xfvn0VGhqqoKAgRUREKCEhQZLvny0KW5sud8w6lYeQkBBFRkZq+/btXtfbvn27KleurODgYI/lZ6bbCym/majMGTdQTpw4Uf/3f/+n/v37a/z48QoNDVWJEiU0bNgwZWdnWx/TqVOn9O2333rM9f3www9r7ty5GjZsmG688UaFhITI5XKpW7duPo0hPT1dCQkJCg4O1rhx4xQbG6uAgABt3bpVjz/++AXZD8Cmxo0bO7NO5aegB1y5XC4tWbJEmzZt0rvvvquVK1eqf//+eu6557Rp0ybn27rC6tq1qyZMmKD9+/erTJkyeuedd9S9e3fnm9Cc461nz57q06dPnn1cd911hRrDf/7zH0n/+2C0fv163XnnnWrevLleeuklRUZGqmTJkpo7d65ef/11n/osbB0CLraYmBj17NlTs2bNyvN+xOzsbLlcLn3wwQd5fh44n5qwYMEC9e3bVx06dNDIkSNVvnx5+fn5adKkSc69Zeeja9euGjVqlBYvXqxhw4bpzTffVEhIiG6//XaP/SlfvrwWLlyYZx953Vt2Ls6uK1lZWbr11luVlpamxx9/XLVq1VLp0qW1Z88e9e3b16e6YKM2Xe4IGvlo166dZs+erU8//dSZOepM69evV2pqqnOj4bmqWrWqsrOztXv3btWoUcNZ/v3335/3mPOyZMkStWzZUnPmzPFYnp6e7jH9m83tHTt2zPm2NmdZnz599NxzzznLjh8/nmte//w+aK1du1YHDhzQsmXL1Lx5c2d5zow9QHGWUwu+++47Z/ID6fQN1+np6bmen9OkSRM1adJEEyZM0Ouvv64ePXrojTfe0MCBA/Ps/1yf0Nu1a1clJiZq6dKlqlChgg4fPuxxs2ZERITKlCmjrKws3XLLLefUty+OHDmi5cuXKyoqynk/li5dqoCAAK1cudJjSt65c+fmen1+++trHQIuJU8//bQWLFigKVOm5GqLjY2VMUbR0dGqWbNmvn3k1JDvv//eY/anzMxMpaamenwxsGTJEsXExGjZsmUex9KYMWM8+jzXuhIdHa3GjRtr0aJFeuihh7Rs2TJ16NDB43iOjY3V6tWr1axZswvyhW3ODdw5n0927Nihb7/9VvPnz/e4+fvMWaly5Le/51KbrlRcOpWPkSNHKjAwUIMHD9aBAwc82tLS0nT//ferVKlSztSR5yrnP/pLL73ksTwpKen8BpwPPz8/jzMc0unrIPN66mhhbdu2TcOGDVO5cuU0ZMgQr2NISkrKNTVt6dKlJSnXH/6cb2rO7OPkyZO53jugOGrTpo0k5ZqtaerUqZLkzER38ODBXMdRgwYNJMnr5VP5HVf5ufbaa1WvXj0tWrRIixYtUmRkpEfA9/Pz0z333KOlS5c63xCead++fT5tJy/Hjh1Tr169lJaWpqeeesr54+7n5yeXy+VRM1JTU/N8MF/p0qXz3Fdf6xBwKYmNjVXPnj318ssv55q16e6775afn58SExNz/d82xjifXRo1aqSwsDDNnj1bmZmZzjoLFy7MNW1sXn9vN2/erI0bN3qsV6pUKUm+1xXp9JcYmzZt0quvvqr9+/d7XDYlSV26dFFWVpbGjx+f67WZmZmF+lLg9ddf1yuvvKIbb7xRN998s6S899UYoxkzZuR6vbfPJ77WpisVZzTyUaNGDc2fP189evRQvXr1NGDAAEVHRys1NVVz5szR/v379c9//lOxsbHn1X9cXJzuueceTZ8+XQcOHFCTJk30r3/9S99++62kc/+2ID/t2rXTuHHj1K9fPzVt2lQ7duzQwoULvT5k0Bfr16/X8ePHnRvMN2zYoHfeeUchISFavny5Klas6DGG5ORkhYSEqHbt2tq4caNWr17tTO2Zo0GDBvLz89OUKVN06NAhud1utWrVSk2bNlW5cuXUp08fDR06VC6XS8nJybkKK1Ac1a9fX3369NGsWbOcywQ///xzzZ8/Xx06dHC+gZw/f75eeukldezYUbGxsfrzzz81e/ZsBQcHO2ElL3FxcZKkp556St26dVPJkiXVvn175w9nXrp27arRo0crICBAAwYMcCaUyDF58mStWbNGN9xwgwYNGqTatWsrLS1NW7du1erVq5WWllbgfu/Zs0cLFiyQdPosRkpKihYvXqzff/9dw4cP9zhb3LZtW02dOlW333677r33Xu3du1cvvviiqlevnusS17i4OK1evVpTp05VpUqVFB0drRtuuMHnOgRcap566iklJydr165dqlOnjrM8NjZWf/vb3zRq1CilpqaqQ4cOKlOmjHbv3q3ly5frvvvu04gRI3TVVVdp7Nixevjhh9WqVSt16dJFqampmjdvnmJjYz0+b7Rr107Lli1Tx44d1bZtW+3evVv/+Mc/VLt2beceB+n0JeK1a9fWokWLVLNmTYWGhqpu3boel02frUuXLhoxYoRGjBih0NDQXGdEExISNHjwYE2aNElfffWVbrvtNpUsWVLfffedFi9erBkzZuR6UHBelixZoqCgIJ08eVJ79uzRypUrtWHDBtWvX1+LFy921qtVq5ZiY2M1YsQI7dmzR8HBwVq6dGmez+zIqaNDhw5V69at5efnp27dup1TbbpiXfR5roqZ7du3m+7du5vIyEhTsmRJU7FiRdO9e3ezY8eOXOt6m1rt7OnejDHm6NGjZsiQISY0NNQEBQWZDh06ONPATZ482Vkvv+lt85oeMiEhwWOquuPHj5vhw4ebyMhIExgYaJo1a2Y2btyYa71znd4256dkyZImIiLCNG/e3EyYMMHs3bs312sOHjxo+vXrZ8LDw01QUJBp3bq12blzZ66pNY0xZvbs2SYmJsb4+fl5THW7YcMG06RJExMYGGgqVapkHnvsMbNy5cp8p8MFLgVnTlfpzalTp0xiYqKJjo42JUuWNFFRUWbUqFEeUzdv3brVdO/e3VSpUsW43W5Tvnx5065dO7NlyxaPvpTHlJPjx483lStXNiVKlPCoJXkdg8YY89133znH+KeffprnmP/44w8zZMgQExUV5dTGm2++2cyaNavA9yVnem5JxuVymeDgYFOnTh0zaNAgs3nz5jxfM2fOHFOjRg3jdrtNrVq1zNy5c/Osqzt37jTNmzc3gYGBRpKzf+dSh4Ci4K1e9OnTx0jymN42x9KlS81NN91kSpcubUqXLm1q1aplhgwZYnbt2uWx3vPPP2+qVq1q3G63ady4sdmwYYOJi4szt99+u7NOdna2mThxorNew4YNzYoVK0yfPn1M1apVPfr77LPPTFxcnLnqqqs86k5ex2WOZs2a5Tmd95lmzZpl4uLiTGBgoClTpoypV6+eeeyxx8yvv/6a72vO3G7OT0BAgLn66qtNu3btzKuvvprnVPgpKSnmlltuMUFBQSY8PNwMGjTIbNu2LdfnoczMTPPwww+biIgI43K5PPbP19p0pXIZw9fCl5KvvvpKDRs21IIFC9SjR4+iHg4AALgMZWdnKyIiQnfffbdmz55d1MPBZYp7NIrQmY+4zzF9+nSVKFHC45poAACA83X8+PFclxu/9tprSktLU4sWLYpmULgicI9GEXrmmWf05ZdfqmXLlvL399cHH3ygDz74QPfdd5+ioqKKengAAOAysGnTJj3yyCPq3LmzwsLCtHXrVs2ZM0d169ZV586di3p4uIxx6VQRWrVqlRITE5WSkqIjR46oSpUq6tWrl5566imPp3cCAACcr9TUVA0dOlSff/650tLSFBoaqjZt2mjy5MkqX758UQ8PlzGCBgAAAADruEcDAAAAgHUEDQAAAADWETQAAAAAWOfzHce2nlQNoPCK661V1JGCFfRvy3sIW4pjHSkO//85hnGl8KWGcEYDAAAAgHUEDQAAAADWETQAAAAAWEfQAAAAAGAdQQMAAACAdQQNAAAAANYRNAAAAABY5/NzNAAAFx5z7APFG8cw8D+c0QAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWEfQAAAAAGAdQQMAAACAdQQNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWEfQAAAAAGAdQQMAAACAdQQNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWEfQAAAAAGAdQQMAAACAdQQNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWEfQAAAAAGAdQQMAAACAdQQNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFjnX9QDgF033HCD1/YnnnjCa3tkZKTX9kOHDnltT0pK8touSe+9957XdmNMgX0AuHCoIwAKgxqCHJzRAAAAAGAdQQMAAACAdQQNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1rmMjxMFu1yuCz0W+KBfv35e2zt16uS1vU2bNl7bL8a80aGhoV7b09PTL/gYirviOr83deTSQB2BVDzrCDXk0kANgeTbvxNnNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHX+RT0AeLrrrru8ts+cOdNr+1VXXeW1/Z133vHavnXrVq/twcHBXtuHDBnitR3AhUcdAVAY1BDYwhkNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHc/RuMT06tXLa3tGRobX9jvuuMNr+5o1a855TGeqVq1aobYvSZmZmYUaAwDvqCMACoMaAls4owEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjgf2XUQdOnQocJ277rrLa/uoUaO8thf2ITh169b12r5q1Sqv7ffee2+B2zhy5Mg5jQnA/1BHTqOOAOeHGnIaNeTi4IwGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwzmWMMT6t6HJd6LEUewW9R+vWrSuwj6ysLK/tbdq08dqekZHhtb1UqVJe27dt2+a1fd68eV7b77vvPq/tktS+fXuv7du3by+wjyudj4ftJYc6UjDqCHXkYimOdYQaUjBqCDXkYvGlhnBGAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWOdf1AO4nERGRnptb9asWYF9PP74417bC5qbuiAFvb5GjRpe26dOneq1PSoqqsAxNGzY0Gs7c1fjSkYdoY4AhUENoYZcSjijAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArOM5GhbddtttXtvT09ML7CM5OdnSaPLWqFEjr+2TJk3y2t60aVObwwFwFuoIgMKghuBSwhkNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHc/RsGjHjh1e24OCggrsY+PGjYXaRkhIiNf2+Pj4AsfgzbZt27y2R0VFFdjH/v37CzUG4HJGHaGOAIVBDaGGXEo4owEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKxzGWOMTyu6XBd6LMVeQe/RokWLCuyjU6dOtoaTp59//tlr++TJk722z50712v7N998U+AYGjZs6LU9PT29wD6udD4etpcc6kjBqCPUkYulONYRakjBqCHUkIvFlxrCGQ0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWEfQAAAAAGCdf1EP4HJS0HzC48aNK7CPo0ePem2PjIz02v7+++97bX/++ecLHAOAokMdAVAY1BBcSjijAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALDOZQp6skvOii7XhR4LLgO7d+8ucJ2GDRt6bU9PT7c0msuXj4ftJYc6Al9QRy6O4lhHqCHwBTXk4vClhnBGAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADWETQAAAAAWOdf1ANA8VKxYkWv7SEhIRdpJACKK+oIgMKghhQfnNEAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADW8RwNnJOgoCCv7QEBARdpJACKK+oIgMKghhQfnNEAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgHUEDAAAAgHUEDQAAAADW8RwNnJOTJ096bc/MzLxIIwFQXFFHABQGNaT44IwGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjudo4JyEhoZ6bf/yyy8L7CM9Pd3SaAAUR9QRAIVBDSk+OKMBAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACs4zkasMrtdhe4TokS3vNtdna2reEAKIaoIwAKgxpy6eCMBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI7naOCc1KpVy2t7kyZNCuwjODjYa3t6evq5DAlAMUMdAVAY1JDigzMaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArCNoAAAAALCOoAEAAADAOoIGAAAAAOt4YB/OSUEPyQGAglBHABQGNaT44IwGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjudo4Jz89ttvXtt37txZYB8ZGRm2hgOgGKKOACgMakjxwRkNAAAAANYRNAAAAABYR9AAAAAAYB1BAwAAAIB1BA0AAAAA1hE0AAAAAFhH0AAAAABgncsYY3xa0eW60GMB4CMfD9tLDnUEuHQUxzpCDQEuHb7UEM5oAAAAALCOoAEAAADAOoIGAAAAAOsIGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA63x+jgYAAAAA+IozGgAAAACsI2gAAAAAsI6gAQAAAMA6ggYAAAAA6wgaAAAAAKwjaAAAAACwjqABAAAAwDqCBgAAAADrCBoAAAAArPt/LWlGPOq27X8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_loader, test_loader = MNIST_loaders()\n",
        "x, y = next(iter(train_loader))\n",
        "x_pos_sample = gen_pos_data(x, y)[0]\n",
        "x_neg_sample = gen_neg_data(x, y)[0]\n",
        "reshaped_org = x[0].cpu().reshape(28, 28)\n",
        "reshaped_pos = x_pos_sample.cpu().reshape(28, 28)\n",
        "reshaped_neg = x_neg_sample.cpu().reshape(28, 28)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "fig.add_subplot(1, 3, 1)\n",
        "plt.imshow(reshaped_org, cmap=\"gray\")\n",
        "plt.axis('off')\n",
        "plt.title(\"Original Data\")\n",
        "\n",
        "fig.add_subplot(1, 3, 2)\n",
        "plt.imshow(reshaped_pos, cmap=\"gray\")\n",
        "plt.axis('off')\n",
        "plt.title(\"Positive Data\")\n",
        "\n",
        "fig.add_subplot(1, 3, 3)\n",
        "plt.imshow(reshaped_neg, cmap=\"gray\")\n",
        "plt.axis('off')\n",
        "plt.title(\"Negative Data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWUSIfaOH5mY"
      },
      "source": [
        "Now we need to create FF_Net and FF_Layer classes to build the Network and implement the Forward-Forward algorithm.\n",
        "We implemented a neural network with two hidden layer, first one has 512 neurons and the second one has 256 neurons.\n",
        "In predict part we generate labeled images with every 10 labels, then we calculate total goodness of layers with this labeled image, in the final step we choose label which maximize total goodness as prediction result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "STnJvm3WZxn_"
      },
      "outputs": [],
      "source": [
        "# Define a Feedforward Neural Network class that inherits from torch.nn.Module\n",
        "class FF_Net(torch.nn.Module):\n",
        "\n",
        "    # Constructor method\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize layers list\n",
        "        self.layers = []\n",
        "\n",
        "        # Add two fully connected layers to the network architecture\n",
        "        # with input size 784, output size 512, and 512 to 256, both on GPU\n",
        "        self.layers.append(FF_Layer(784, 512).cuda())\n",
        "        self.layers.append(FF_Layer(512, 256).cuda())\n",
        "\n",
        "    # Prediction method for the network\n",
        "    def predict(self, x):\n",
        "        # List to store goodness for each label\n",
        "        labels_goodness = []\n",
        "\n",
        "        # Loop through each label (0 to 9)\n",
        "        for label in range(10):\n",
        "            # Generate positive data for the current label\n",
        "            output = gen_pos_data(x, label)\n",
        "            total_goodness = 0\n",
        "\n",
        "            # Iterate through layers and calculate goodness\n",
        "            for layer in self.layers:\n",
        "                output = layer(output)\n",
        "                total_goodness += self.compute_goodness(output)\n",
        "\n",
        "            # Append total goodness for the current label\n",
        "            labels_goodness.append(total_goodness.unsqueeze(1))\n",
        "\n",
        "        # Concatenate goodness values for each label\n",
        "        labels_goodness = torch.cat(labels_goodness, 1)\n",
        "\n",
        "        # Determine the label with the maximum goodness\n",
        "        predicted_label = labels_goodness.argmax(1)\n",
        "\n",
        "        # Return the predicted label\n",
        "        return predicted_label\n",
        "\n",
        "    # Training method for the network\n",
        "    def train(self, x_pos, x_neg):\n",
        "        # Initialize positive and negative data\n",
        "        h_pos, h_neg = x_pos, x_neg\n",
        "\n",
        "        # Iterate through layers for training\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            print('training layer', i, '...')\n",
        "            h_pos, h_neg = layer.train(h_pos, h_neg)\n",
        "\n",
        "    # Compute goodness method\n",
        "    def compute_goodness(self, model_output):\n",
        "        # Calculate goodness as the mean of squared values along the second dimension\n",
        "        goodness = torch.mean(model_output.pow(2), dim=1)\n",
        "        return goodness\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBXCyTEIL3kb"
      },
      "source": [
        "in this part we have two important function, the first one is forward in which we perform forward pass of layer. we used relu as activation function. second function is train, in this function firstly we derived goodness of positive and negative data, then we used a custom loss function as mentioned in question.\n",
        "**this loss function is suitable for this algorithm because \"the aim of the learning is to make the goodness be well above some thereshold value for real data and well below that value for negative data\". in the paper probability of positive data is defined as: $$p(positive) = \\sigma \\big(\\sum_j y_j^2 - \\theta \\big) $$\n",
        "this loss function is equal to calculate binary cross entropy using this probability function.\n",
        "in the last part, with using of gradient decent we updated the parameters in a way that minimizing loss function of this layer it self."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "28OjaoqJaBaN"
      },
      "outputs": [],
      "source": [
        "class FF_Layer(nn.Linear):\n",
        "    def __init__(self, in_features, out_features,\n",
        "                 bias=True, device=None, dtype=None):\n",
        "        super().__init__(in_features, out_features, bias, device, dtype)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.opt = Adam(self.parameters(), lr=0.03)\n",
        "        self.num_epochs = 1500\n",
        "        self.threshold = 4.0\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Normalize input along the second dimension (row-wise) to have unit L2 norm\n",
        "        x_normalized = x / (x.norm(2, dim=1, keepdim=True) + 1e-6)\n",
        "\n",
        "        # Perform linear transformation and add bias\n",
        "        linear_output = torch.mm(x_normalized, self.weight.T) + self.bias.unsqueeze(0)\n",
        "\n",
        "        # Apply ReLU activation function\n",
        "        activated_output = self.relu(linear_output)\n",
        "\n",
        "        return activated_output\n",
        "\n",
        "    def train(self, x_pos, x_neg):\n",
        "        for i in tqdm(range(self.num_epochs)):\n",
        "            # Compute goodness of positive and negative data\n",
        "            model_output = self.forward(x_pos)\n",
        "            g_pos = self.compute_goodness(model_output)\n",
        "            model_output = self.forward(x_neg)\n",
        "            g_neg = self.compute_goodness(model_output)\n",
        "\n",
        "            # Compute Loss function\n",
        "            loss = self.compute_loss(g_pos, g_neg)\n",
        "\n",
        "            # optimization step\n",
        "            self.optimize(loss)\n",
        "\n",
        "        # Return the forward pass results for positive and negative data\n",
        "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n",
        "\n",
        "    def compute_goodness(self, model_output):\n",
        "        goodness = torch.mean(model_output.pow(2), dim=1)\n",
        "        return goodness\n",
        "\n",
        "    def compute_loss(self, g_pos, g_neg):\n",
        "        loss = torch.log(1 + torch.exp(torch.cat([self.threshold - g_pos, g_neg - self.threshold]))).mean()\n",
        "        return loss\n",
        "\n",
        "    def optimize(self, loss):\n",
        "        self.opt.zero_grad()\n",
        "        loss.backward()\n",
        "        self.opt.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0Ehk9eSXArN"
      },
      "source": [
        "Now we want to evaluate the algorithm by training the Mnist data set on it. As you can see the results are acceptable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PTDW83maCk7",
        "outputId": "71d36ede-8222-4cbc-9ea0-93e5352ea881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training layer 0 ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1500/1500 [01:19<00:00, 18.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training layer 1 ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1500/1500 [00:31<00:00, 48.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.9328199625015259\n",
            "Train error: 0.06718003749847412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-4ca4d7af3f27>:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_accuracy = (torch.tensor(net.predict(x_train)) == y_train).float().mean().item()\n"
          ]
        }
      ],
      "source": [
        "# Set a manual seed for reproducibility\n",
        "torch.manual_seed(23)\n",
        "\n",
        "# Load MNIST data into train and test loaders\n",
        "train_loader, test_loader = MNIST_loaders()\n",
        "\n",
        "# Create an instance of the FF_Net class\n",
        "net = FF_Net()\n",
        "\n",
        "# Load a batch of training data and move it to the GPU\n",
        "x_train, y_train = next(iter(train_loader))\n",
        "x_train, y_train = x_train.cuda(), y_train.cuda()\n",
        "\n",
        "# Generate positive and negative data for training\n",
        "x_pos = gen_pos_data(x_train, y_train)\n",
        "x_neg = gen_neg_data(x_train, y_train)\n",
        "\n",
        "# Train the neural network on the generated data\n",
        "net.train(x_pos, x_neg)\n",
        "\n",
        "# Evaluate the training accuracy and error\n",
        "train_accuracy = (torch.tensor(net.predict(x_train)) == y_train).float().mean().item()\n",
        "print(f'Train accuracy: {train_accuracy}')\n",
        "\n",
        "train_error = 1.0 - train_accuracy\n",
        "print(f'Train error: {train_error}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3OSnjQIusTL",
        "outputId": "bd878533-6673-4ce7-a59a-ea507009c6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9319999814033508\n",
            "Test error: 0.06800001859664917\n"
          ]
        }
      ],
      "source": [
        "# Load a batch of test data and move it to the GPU\n",
        "x_test, y_test = next(iter(test_loader))\n",
        "x_test, y_test = x_test.cuda(), y_test.cuda()\n",
        "\n",
        "# Evaluate the test accuracy and error\n",
        "test_accuracy = net.predict(x_test).eq(y_test).float().mean().item()\n",
        "print(f'Test accuracy: {test_accuracy}')\n",
        "\n",
        "test_error = 1.0 - test_accuracy\n",
        "print(f'Test error: {test_error}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyugDFgJhAww"
      },
      "source": [
        "**Unsupervised method:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "5Nvq564kicMc"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def gen_mask(shape, itr = 10):\n",
        "\n",
        "    # Create filters as mentioned in paper\n",
        "    filter_1 = torch.tensor(((0, 0, 0), (0.25, 0.5, 0.25), (0, 0, 0)), dtype=torch.float32)\n",
        "    filter_2 = filter_1.T\n",
        "\n",
        "    # Create a random binary image as a PyTorch tensor\n",
        "    image = torch.randint(0, 2, size=shape, dtype=torch.float32)\n",
        "\n",
        "    # Blur the image with the specified filter\n",
        "    for i in range(itr):\n",
        "        image = torch.abs(F.conv2d(image.unsqueeze(0).unsqueeze(0), filter_1.unsqueeze(0).unsqueeze(0), padding=1)[0][0] / filter_1.sum())\n",
        "        image = torch.abs(F.conv2d(image.unsqueeze(0).unsqueeze(0), filter_2.unsqueeze(0).unsqueeze(0), padding=1)[0][0] / filter_2.sum())\n",
        "\n",
        "    # Binarize the blurred image, i.e., threshold it at 0.5\n",
        "    mask = torch.round(image).byte()\n",
        "\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "CQxFgRLJiivs"
      },
      "outputs": [],
      "source": [
        "def gen_neg_img(image_1, image_2):\n",
        "\n",
        "    # Create a binary mask\n",
        "    mask = gen_mask(image_1.shape)\n",
        "\n",
        "    # Element-wise multiplication with the mask\n",
        "    masked_image_1 = image_1 * mask\n",
        "    masked_image_2 = image_2 * (1 - mask)\n",
        "\n",
        "    # Element-wise addition of masked images\n",
        "    result_image = masked_image_1 + masked_image_2\n",
        "\n",
        "    return result_image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part we want to show one example of how negative data are constructed."
      ],
      "metadata": {
        "id": "z---1Q08gNZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "065fjmrWiyAi",
        "outputId": "da177336-5384-4062-e8a7-f4d9174c6110"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the MNIST dataset\n",
        "train_loader, test_loader = MNIST_loaders()\n",
        "x, y = next(iter(train_loader))\n",
        "\n",
        "# Reshape data from flatten to 28*28\n",
        "images = torch.reshape(x, (x.shape[0],28,28))\n",
        "\n",
        "# Get two random images from training data\n",
        "image_1 = images[np.random.randint(len(images))]\n",
        "image_2 = images[np.random.randint(len(images))]\n",
        "\n",
        "# Generate a random mask\n",
        "mask = gen_mask((28, 28))\n",
        "\n",
        "# Generating a negative input using mask and two random images\n",
        "image = gen_neg_img(image_1, image_2)\n",
        "\n",
        "# Show the results\n",
        "images = [image_1, mask, image, 1-mask, image_2]\n",
        "names = [\"image 1\", \"mask\", \"negative data\", \"1-mask\", \"image 2\"]\n",
        "\n",
        "fig, axes = plt.subplots(1, 5)\n",
        "\n",
        "for ax, image, name in zip(axes, images, names):\n",
        "    ax.imshow(image, cmap='gray')\n",
        "    ax.axis('off')\n",
        "    ax.set_title(name)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now in this block we generated all negative data"
      ],
      "metadata": {
        "id": "1YrQtiTCjXC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_neg_data_unsupervised(images):\n",
        "    neg_images = []\n",
        "\n",
        "    # Get the batch size\n",
        "    batch_size = images.shape[0]\n",
        "\n",
        "    # Generate negative images by combining random pairs\n",
        "    for _ in range(batch_size):\n",
        "        idx1, idx2 = torch.randint(0, batch_size, size=(2,))\n",
        "        neg_images.append(gen_neg_img(images[idx1].squeeze(), images[idx2].squeeze()))\n",
        "\n",
        "    # Stack the negative images into a single tensor and add a channel dimension\n",
        "    neg_images = torch.unsqueeze(torch.stack(neg_images), dim=1)\n",
        "\n",
        "    return neg_images"
      ],
      "metadata": {
        "id": "Hf4YV_Mcj8LJ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this block we define a new class to make the structure of out neural network to train and predict the data."
      ],
      "metadata": {
        "id": "S-0D-o3dtP7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Feedforward Neural Network class that inherits from torch.nn.Module\n",
        "class FF_Net_Unsupervised(torch.nn.Module):\n",
        "\n",
        "    # Constructor method\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize layers list\n",
        "        self.layers = []\n",
        "\n",
        "        # Add two fully connected layers to the network architecture\n",
        "        # with input size 784, output size 512, and 512 to 256, both on GPU\n",
        "        self.layers.append(FF_Layer(784, 512).cuda())\n",
        "        self.layers.append(FF_Layer(512, 256).cuda())\n",
        "\n",
        "    # Prediction method for the network\n",
        "    def predict(self, x):\n",
        "        # List to store goodness for each label\n",
        "        labels_goodness = []\n",
        "\n",
        "        # Loop through each label (0 to 9)\n",
        "        for label in range(10):\n",
        "            # Generate positive data for the current label\n",
        "            output = gen_pos_data(x, label)\n",
        "            total_goodness = 0\n",
        "\n",
        "            # Iterate through layers and calculate goodness\n",
        "            for layer in self.layers:\n",
        "                output = layer(output)\n",
        "\n",
        "\n",
        "        # Return the predicted label\n",
        "        return output\n",
        "\n",
        "    # Training method for the network\n",
        "    def train(self, x_pos, x_neg):\n",
        "        # Initialize positive and negative data\n",
        "        h_pos, h_neg = x_pos, x_neg\n",
        "\n",
        "        # Iterate through layers for training\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            print('training layer', i, '...')\n",
        "            h_pos, h_neg = layer.train(h_pos, h_neg)\n",
        "\n",
        "    # Compute goodness method\n",
        "    def compute_goodness(self, model_output):\n",
        "        # Calculate goodness as the mean of squared values along the second dimension\n",
        "        goodness = torch.mean(model_output.pow(2), dim=1)\n",
        "        return goodness"
      ],
      "metadata": {
        "id": "tSLUqdvEtH6j"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a manual seed for reproducibility\n",
        "torch.manual_seed(23)\n",
        "\n",
        "# Load MNIST data into train and test loaders\n",
        "train_loader, test_loader = MNIST_loaders()\n",
        "\n",
        "# Create an instance of the FF_Net class\n",
        "net = FF_Net_Unsupervised()\n",
        "\n",
        "# Load a batch of training data and move it to the GPU\n",
        "x_train, y_train = next(iter(train_loader))\n",
        "\n",
        "# Reshape data from flatten to 28*28\n",
        "x_train = torch.reshape(x_train, (x_train.shape[0],28,28))\n",
        "\n",
        "# Generate positive and negative data for training\n",
        "x_pos = x_train\n",
        "x_neg = gen_neg_data_unsupervised(x_train)\n",
        "\n",
        "# Flatten the images\n",
        "x_train = torch.reshape(x_train, (x_train.shape[0],784))\n",
        "x_pos = torch.reshape(x_pos, (x_pos.shape[0],784))\n",
        "x_neg = torch.reshape(x_neg, (x_neg.shape[0],784))\n"
      ],
      "metadata": {
        "id": "22d4BA4DcOYU"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the network\n",
        "x_pos = x_pos.cuda()\n",
        "x_neg = x_neg.cuda()\n",
        "\n",
        "net.train(x_pos, x_neg)\n",
        "\n",
        "x_train = x_train.cuda()\n",
        "\n",
        "# output of two hidden layer after training\n",
        "output_FF = net.predict(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WlfqFMWw4_9",
        "outputId": "eac60c3d-9f79-46b6-919d-3dd7f077a666"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training layer 0 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1500/1500 [01:33<00:00, 15.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training layer 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1500/1500 [00:34<00:00, 43.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of our FF network for each of the traing data is a feature vector with size of 256, we hope this features are useful to classify data using a linear classifier in next part .now we need define a linear classifier to clasify the data."
      ],
      "metadata": {
        "id": "SZhSBBj4zwpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Move data to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "output_FF = output_FF.to(device)\n",
        "y_train = y_train.to(device)\n",
        "\n",
        "# Define a linear classifier\n",
        "class LinearClassifier(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LinearClassifier, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Create an instance of the linear classifier\n",
        "input_size = 256\n",
        "num_classes = 10\n",
        "classifier = LinearClassifier(input_size, num_classes)\n",
        "classifier = classifier.to(device)  # Move model to GPU if available\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = classifier(output_FF)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print the loss every 100 epochs\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiTrXj2E3bIv",
        "outputId": "cb818d22-566c-435f-a23e-3dd05d022023"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 2.2793\n",
            "Epoch [200/1000], Loss: 2.2793\n",
            "Epoch [300/1000], Loss: 2.2793\n",
            "Epoch [400/1000], Loss: 2.2793\n",
            "Epoch [500/1000], Loss: 2.2793\n",
            "Epoch [600/1000], Loss: 2.2793\n",
            "Epoch [700/1000], Loss: 2.2793\n",
            "Epoch [800/1000], Loss: 2.2793\n",
            "Epoch [900/1000], Loss: 2.2793\n",
            "Epoch [1000/1000], Loss: 2.2793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to calculate the test accuracy."
      ],
      "metadata": {
        "id": "o2FD2Yn27flh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = next(iter(test_loader))\n",
        "x_test, y_test = x_test.cuda(), y_test.cuda()\n",
        "\n",
        "output_FF = net.predict(x_test)\n",
        "\n",
        "outputs = classifier(output_FF)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "accuracy = (predicted == y_test.to(device)).float().mean()\n",
        "print(f'Test Accuracy: {accuracy.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYSb872F7e_F",
        "outputId": "9ed0f37b-ea0a-424e-80ba-b967b06bf323"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.0847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WUKqAQipz469"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}